1. Setup and Imports

import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

from multilingua_ocr.models import DocumentEncoder, MultilingualDecoder
from multilingua_ocr.evaluation import OCRMetrics, CulturalPreservationMetrics

2. Model Architecture Analysis

def visualize_model_architecture(encoder, decoder):
    def count_parameters(model):
        return sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    # Display model statistics
    print("Model Architecture Statistics:")
    print(f"Encoder parameters: {count_parameters(encoder):,}")
    print(f"Decoder parameters: {count_parameters(decoder):,}")
    
    # Visualize layer dimensions
    def plot_layer_dims(model, title):
        layers = [(name, p.shape) for name, p in model.named_parameters()]
        layer_sizes = [np.prod(shape) for _, shape in layers]
        
        plt.figure(figsize=(12, 6))
        plt.bar(range(len(layer_sizes)), layer_sizes)
        plt.title(f'{title} Layer Dimensions')
        plt.xlabel('Layer Index')
        plt.ylabel('Number of Parameters')
        plt.yscale('log')
        plt.tight_layout()
        plt.show()
    
    plot_layer_dims(encoder, 'Encoder')
    plot_layer_dims(decoder, 'Decoder')

3. Attention Analysis

def visualize_attention_patterns(model_output, tokens, save_path=None):
    attention_weights = model_output['attention_weights'][0]  # First head
    
    plt.figure(figsize=(12, 8))
    sns.heatmap(
        attention_weights.cpu().numpy(),
        xticklabels=tokens,
        yticklabels=tokens,
        cmap='viridis'
    )
    plt.title('Script-Aware Attention Patterns')
    plt.xlabel('Target Tokens')
    plt.ylabel('Source Tokens')
    
    if save_path:
        plt.savefig(save_path)
    plt.show()

4. Cultural Embedding Analysis

def analyze_cultural_embeddings(embeddings, labels):
    # Reduce dimensionality for visualization
    from sklearn.manifold import TSNE
    tsne = TSNE(n_components=2, random_state=42)
    reduced_embeddings = tsne.fit_transform(embeddings.cpu().numpy())
    
    # Plot embeddings
    plt.figure(figsize=(12, 8))
    scatter = plt.scatter(
        reduced_embeddings[:, 0],
        reduced_embeddings[:, 1],
        c=labels,
        cmap='tab20'
    )
    plt.title('Cultural Embedding Space')
    plt.colorbar(scatter)
    plt.tight_layout()
    plt.show()

5. Performance Analysis

def analyze_performance_by_condition(results, degradation_levels):
    metrics = ['cer', 'cca', 'sps']
    
    plt.figure(figsize=(15, 5))
    for i, metric in enumerate(metrics, 1):
        plt.subplot(1, 3, i)
        sns.boxplot(x='degradation_level', y=metric, data=results)
        plt.title(f'{metric.upper()} by Degradation Level')
        plt.xlabel('Degradation Level')
        plt.ylabel(metric.upper())
    
    plt.tight_layout()
    plt.show()

