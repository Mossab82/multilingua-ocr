1. Setup and Imports

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from PIL import Image
import cv2
from collections import Counter
import torch

from multilingua_ocr.data import DocumentPreprocessor, DegradationAnalyzer
from multilingua_ocr.core import load_cultural_ontology

2. Dataset Overview

# Load dataset metadata
data_root = Path("path/to/data")
train_meta = pd.read_csv(data_root / "train_metadata.csv")
val_meta = pd.read_csv(data_root / "val_metadata.csv")
test_meta = pd.read_csv(data_root / "test_metadata.csv")

# Display basic statistics
print("Dataset Statistics:")
print(f"Training samples: {len(train_meta)}")
print(f"Validation samples: {len(val_meta)}")
print(f"Test samples: {len(test_meta)}")

3. Language Distribution Analysis

def plot_language_distribution(metadata):
    language_pairs = metadata['language_pair'].value_counts()
    plt.figure(figsize=(10, 6))
    language_pairs.plot(kind='bar')
    plt.title('Distribution of Language Pairs')
    plt.xlabel('Language Pair')
    plt.ylabel('Count')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

plot_language_distribution(train_meta)

4. Document Condition Analysis

degradation_analyzer = DegradationAnalyzer()

def analyze_document_condition(image_path):
    image = cv2.imread(str(image_path))
    degradation_map = degradation_analyzer(image)
    
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.title('Original Document')
    plt.axis('off')
    
    plt.subplot(1, 3, 2)
    plt.imshow(degradation_map, cmap='YlOrRd')
    plt.title('Degradation Map')
    plt.colorbar(label='Degradation Level')
    plt.axis('off')
    
    plt.subplot(1, 3, 3)
    plt.hist(degradation_map.ravel(), bins=50)
    plt.title('Degradation Distribution')
    plt.xlabel('Degradation Level')
    plt.ylabel('Frequency')
    
    plt.tight_layout()
    plt.show()

5. Cultural Concept Analysis

# Load cultural ontology
ontology = load_cultural_ontology(data_root / "cultural_ontology.yaml")

def analyze_cultural_concepts(texts, ontology):
    concept_counts = Counter()
    for text in texts:
        for category, concepts in ontology.items():
            for concept in concepts:
                if concept in text:
                    concept_counts[category] += 1
    
    # Plot concept distribution
    plt.figure(figsize=(12, 6))
    categories = list(concept_counts.keys())
    counts = [concept_counts[cat] for cat in categories]
    plt.bar(categories, counts)
    plt.title('Distribution of Cultural Concepts')
    plt.xlabel('Concept Category')
    plt.ylabel('Frequency')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

